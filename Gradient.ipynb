{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a6782c-140f-4c03-832c-c9488ec231ae",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd377fa-a172-4274-9c6e-a7bbb4b39f87",
   "metadata": {},
   "source": [
    "I gradienti sono spesso utilizzati in alcuni algoritmi di apprendimento automatico, come ad esempio la Rete neurale artificiale (NN) o la Regressione logistica, per ottimizzare i parametri del modello durante il processo di addestramento.\n",
    "\n",
    "Questo è fatto utilizzando una tecnica di ottimizzazione nota come gradient descent, in cui il gradiente viene calcolato per la funzione di perdita (che misura quanto il modello è \"sbagliato\") e utilizzato per aggiornare i pesi del modello nella direzione che riduce la perdita. Questo processo viene ripetuto fino a quando non viene raggiunta una certa precisione o il modello non converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00fb99-c9d5-4ad1-a623-2bfd1583a6cb",
   "metadata": {},
   "source": [
    "## Logistic regression Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63264306-07aa-4385-ba8d-0322b25c1c42",
   "metadata": {},
   "source": [
    "Qui è un esempio di come un gradiente potrebbe essere utilizzato per addestrare un modello di regressione logistica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a959bc-08ec-436b-ac27-469e19834a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calcola il gradiente della funzione di perdita\n",
    "def gradient(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta)\n",
    "    gradient = (1/m) * X.T @ (h - y)\n",
    "    return gradient\n",
    "\n",
    "# La funzione di addestramento\n",
    "def train(X, y, theta, learning_rate, num_iters):\n",
    "    m = len(y)\n",
    "    for i in range(num_iters):\n",
    "        # Calcola il gradiente\n",
    "        gradient = gradient(X, y, theta)\n",
    "        \n",
    "        # Aggiorna i pesi del modello utilizzando il gradient descent\n",
    "        theta = theta - learning_rate * gradient\n",
    "        \n",
    "        # Stampa la perdita ogni 100 iterazioni\n",
    "        if i % 100 == 0:\n",
    "            loss = cost(X, y, theta)\n",
    "            print(\"Loss at iteration %d: %f\" % (i, loss))\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ebfbf-d2ee-4092-85cf-af079f8a48c7",
   "metadata": {},
   "source": [
    "Questo è solo un esempio molto semplificato, ma dovrebbe darti un'idea di come un gradiente potrebbe essere utilizzato in un contesto di intelligenza artificiale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ec8cb-9389-407b-90a1-2ecf15fddc78",
   "metadata": {},
   "source": [
    "## Neural Network (NN) Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78db7a-d46f-4559-b1c4-d772c44a23f1",
   "metadata": {},
   "source": [
    "Un esempio di utilizzo del gradiente in una rete neurale artificiale (NN) può essere l'ottimizzazione dei pesi della rete tramite l'algoritmo di gradiente disceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0dbcbc-e110-4e24-80e0-2be33954ad8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b2/kqnx_r5555gfw4sz0bdz9b440000gp/T/ipykernel_60572/871197309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mnum_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# Specificare il numero di variabili di input (input_data.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mnum_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# Specificare il numero di variabili di output (target.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Inizializza i pesi con valori casuali distribuiti normalmente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# Specificare i dati di input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# Specificare i target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.standard_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.cont\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define la funzione di perdita (ad esempio la MSE)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "# Calcola il gradiente della funzione di perdita rispetto ai pesi della rete\n",
    "def gradient(weights, input_data, target):\n",
    "    # Passa i dati di input attraverso la rete\n",
    "    predictions = network_function(input_data, weights)\n",
    "    # Calcola l'errore tra le previsioni e i target\n",
    "    error = mean_squared_error(target, predictions)\n",
    "    # Calcola il gradiente della funzione di perdita rispetto ai pesi\n",
    "    gradient = 2 * (predictions - target) * input_data\n",
    "    return gradient, error\n",
    "\n",
    "# Aggiorna i pesi della rete utilizzando il gradiente disceso\n",
    "def update_weights(weights, gradient, learning_rate):\n",
    "    weights -= learning_rate * gradient\n",
    "    return weights\n",
    "\n",
    "# Esempio di addestramento della rete\n",
    "def train_network(input_data, target, weights, learning_rate, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Calcola il gradiente della funzione di perdita rispetto ai pesi\n",
    "        gradient, error = gradient(weights, input_data, target)\n",
    "        # Aggiorna i pesi utilizzando il gradiente disceso\n",
    "        weights = update_weights(weights, gradient, learning_rate)\n",
    "        # Stampa l'errore per ogni epoch\n",
    "        print(\"Epoch {}: loss = {}\".format(epoch, error))\n",
    "    return weights\n",
    "\n",
    "# Inizializzare i pesi della rete e i dati di input/target\n",
    "num_inputs = ... # Specificare il numero di variabili di input (input_data.shape[1])\n",
    "num_outputs = ... # Specificare il numero di variabili di output (target.shape[1])\n",
    "weights = np.random.randn(num_inputs, num_outputs) # Inizializza i pesi con valori casuali distribuiti normalmente\n",
    "input_data = ... # Specificare i dati di input\n",
    "target = ... # Specificare i target\n",
    "\n",
    "# Iperparametri di addestramento\n",
    "learning_rate = ... # Specificare il learning rate\n",
    "num_epochs = ... # Specificare il numero di epoche\n",
    "\n",
    "# Addestrare la rete per num_epochs\n",
    "trained_weights = train_network(input_data, target, weights, learning_rate, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a91f6c-4dfe-46c9-893c-03a4b04f8e40",
   "metadata": {},
   "source": [
    "In questo esempio, la funzione di perdita viene utilizzata per calcolare l'errore tra le previsioni della rete e i target. Il gradiente della funzione di perdita rispetto ai pesi della rete viene quindi calcolato e utilizzato per aggiornare i pesi della rete tramite l'algoritmo di gradiente disceso. L'addestramento della rete viene eseguito per un determinato numero di epoche (num_epochs), ogni volta calcolando il gradiente, aggiornando i pesi e stampando l'errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a753196-2937-4807-ad59-10d7f5fad0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b61ae6-85a8-4970-81e9-f747bfb92490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
